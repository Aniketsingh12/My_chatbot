{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c700375f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import pypdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfe18336",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader\n",
    "\n",
    "def read_pdf(file_path):\n",
    "    reader = PdfReader(file_path)\n",
    "    text = \"\"\n",
    "    for page in reader.pages:\n",
    "        text += page.extract_text() + \"\\n\"\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "076646f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\A'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\A'\n",
      "C:\\Users\\aniket singh\\AppData\\Local\\Temp\\ipykernel_12532\\2194452306.py:1: SyntaxWarning: invalid escape sequence '\\A'\n",
      "  my_summary = read_pdf(\"data\\AniketSingh_AI_Engineer_resume_R.pdf\")\n"
     ]
    }
   ],
   "source": [
    "my_summary = read_pdf(\"data\\AniketSingh_AI_Engineer_resume_R.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e62ee012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Aniket Singh',\n",
       " 'INDIA',\n",
       " '/ne+91-7985287855 Gmail /♀nednLinkedIn /gtbGithub /g♀bePortfolio',\n",
       " 'Summary',\n",
       " 'AI Engineer specializing in building end-to-end intelligent systems with LLMs, RAG, and MLOps pipelines. Experienced in',\n",
       " 'architecting solutions from high-volume data processing to context-aware conversational agents. Seeking a challenging remote',\n",
       " 'role to solve complex engineering problems and contribute to innovative AI products.',\n",
       " 'Experience',\n",
       " 'AI Engineer June 2024 – Present',\n",
       " 'Acadally Delhi, India (Remote)',\n",
       " '•Adaptive Tutoring System: Architected and developed an AI-driven tutoring platform for grades 5–8, personalizing',\n",
       " 'learning paths to enhance student engagement and educational outcomes.',\n",
       " '•Difficulty Calibration Agent: Engineered a calibration agent using Item Response Theory (IRT) and a RAG pipeline',\n",
       " 'with NCERT textbooks, ensuring precise and context-aware question generation.',\n",
       " '•Context-Aware Question Generator: Developed a generator using fine-tuned LLMs to produce dynamic, Bloom’s',\n",
       " 'Taxonomy–aligned questions that foster critical thinking and deeper student interaction.',\n",
       " '•Text-to-SQL Interface: Built a robust agent that translates natural language queries from educators into SQL,',\n",
       " 'enabling real-time performance analytics and data-driven instruction.',\n",
       " 'Graduate Engineer Trainee April 2024 – June 2024',\n",
       " 'Radius Synergies Delhi, India',\n",
       " '•Predictive Analytics: Contributed to a time-series forecasting model for electricity consumption, supporting strategic',\n",
       " 'energy management and cost-reduction initiatives.',\n",
       " '•High-Volume ETL Pipeline: Engineered a high-throughput ETL pipeline to process over 17 million records daily,',\n",
       " 'significantly accelerating data preparation and model training cycles.',\n",
       " 'Projects',\n",
       " 'MCP AI Assistant - Multi-Source Intelligence Platform *|AI/ML, Full Stack Jan 2024',\n",
       " '•Multi-Source Integration: Architected an AI assistant using Model Context Protocol (MCP) to dynamically query',\n",
       " 'external services (web scraping, search APIs, databases) for real-time, accurate information retrieval.',\n",
       " '•Conversational AI: Implemented a LangChain-powered agent with Groq’s Llama3-8B model, enabling persistent',\n",
       " 'memory and context-aware interactions across user sessions.',\n",
       " '•Full-Stack Development: Developed a full-stack application with Streamlit and Flask frontends, containerized with',\n",
       " 'Docker for seamless, scalable deployment.',\n",
       " 'Technical Expertise',\n",
       " '•Machine Learning & Deep Learning',\n",
       " '•Natural Language Processing (NLP)',\n",
       " '•Generative AI & LLMs•Retrieval-Augmented Generation',\n",
       " '(RAG)',\n",
       " '•Model Context Protocol (MCP)•MLOps & Model Deployment',\n",
       " '•Data Structures & Algorithms',\n",
       " 'Technical Skills',\n",
       " 'Languages: Python (Advanced), C++ (Beginner), SQL (Intermediate)',\n",
       " 'AI/ML Frameworks: PyTorch, TensorFlow, Transformers, LangChain, Scikit-learn',\n",
       " 'MLOps & Cloud: Docker, AWS (EC2, S3, SageMaker), Git/GitHub, Weights & Biases',\n",
       " 'Data Algorithms: Pandas, NumPy, DSA (Arrays, Trees, Graphs, DP), LeetCode (200+ problems)',\n",
       " 'Education',\n",
       " 'PSIT College of Engineering Kanpur, India',\n",
       " 'B.Tech in Computer Science and Engineering 2020 – 2024',\n",
       " 'Bal Bharti School Prayagraj, India',\n",
       " '12th - PCM 2018 – 2020',\n",
       " 'Certifications',\n",
       " '•Google Data Analytics Professional Certificate (Coursera)',\n",
       " '•Data Structures and Algorithms Specialization (Coursera)',\n",
       " '']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_summary.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9bb0738",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Aniket\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d99eea51",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"\"\"\n",
    "You are {name}. You are an AI digital twin designed to represent me in professional conversations. \n",
    "Your goal is to answer questions about my background, skills, and career achievements based on the following summary:\n",
    "\n",
    "{my_summary}\n",
    "\n",
    "Guidelines:\n",
    "1. Speak in the first person (e.g., \"I developed...\", \"In my experience...\").\n",
    "2. Maintain a professional, confident, and helpful tone.\n",
    "3. If asked about something not mentioned in the summary, respond based on what a professional in my field would likely know, or politely state that you'd need to check my full portfolio for specific details.\n",
    "4. Keep responses concise and focused on professional value.\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2cf1bffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(msg  , history):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": msg},\n",
    "    ]\n",
    "    \n",
    "    response = ollama.chat(model=\"deepseek-r1:7b\", messages=messages)['message']['content']\n",
    "    return response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26e5ce7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<think>\\nOkay, so I'm trying to figure out how Aniket can help me with AI-related tasks. He's an AI Engineer with a background in building end-to-end intelligent systems using LLMs, RAG, and MLOps. He has several years of experience, including developing tutoring systems, creating question generators using NLP models, integrating conversational agents, and working on ETL pipelines for data processing.\\n\\nI need to think about how I can leverage Aniket's skills in my current projects or tasks. Let me consider his expertise areas:\\n\\n1. **AI Model Development**: He has experience with LLMs like Llama3-8B and using frameworks such as PyTorch, TensorFlow, and LangChain. If I'm working on a project that involves developing an AI model to solve a specific problem, Aniket can provide guidance or collaborate on building the model.\\n\\n2. **Data Processing Pipelines**: He's worked on high-throughput ETL pipelines for processing large datasets. If my project requires handling big data efficiently, his experience in optimizing and scaling data pipelines would be beneficial.\\n\\n3. **Integration of Third-Party Services**: His work includes integrating external services using Model Context Protocol (MCP) and handling web scraping or search APIs. If my task involves fetching real-time data from various sources, he can offer expertise in setting up these integrations smoothly.\\n\\n4. **Real-Time Analytics and Reporting**: He's involved in translating natural language queries into SQL for real-time analytics. This is useful if I need to develop a system that provides instant insights or reports based on user inputs.\\n\\n5. **AI-Driven Applications**: His work includes creating interactive applications like tutoring systems and question generators, which can be adapted for various AI-driven applications I might be developing.\\n\\n6. **MLOps and Deployment**: He uses tools like Docker, AWS services, Git/GitHub, and Weights & Biases for deploying models. If my project requires setting up a scalable and efficient model deployment environment, his MLOps experience will help ensure the system runs smoothly.\\n\\n7. **NLP Techniques**: His background includes using techniques like Item Response Theory (IRT) and RAG pipelines with NCERT textbooks. This could be useful if I'm working on educational tools or systems that require understanding user queries accurately.\\n\\nNow, considering my role in AI development, I might need to approach Aniket for several reasons:\\n\\n- **Building Models**: If I'm stuck developing a part of an AI model, he can offer insights into the architecture and implementation.\\n- **Optimizing Data Pipelines**: If my project involves handling large datasets, seeking his advice on optimizing data flow could save significant time and resources.\\n- **Integrating External Services**: If my application requires real-time data from various sources, he has experience in setting up these integrations efficiently.\\n- **Real-Time Reporting**: If I need a system that can quickly generate reports based on user queries, his expertise in translating NLP into SQL could be applied here.\\n\\nI should also think about how to communicate with Aniket effectively. Since he's available via email and LinkedIn, using these platforms would be appropriate for setting up meetings or discussing potential projects. It's important to clearly outline my needs so that he can provide the most relevant assistance.\\n\\nAdditionally, I might need to prepare any specific requirements or questions beforehand to make the collaboration more efficient. For example, if I'm asking him about integrating a new feature using MCP or enhancing an ETL pipeline, having detailed use cases ready will help him address them effectively.\\n\\nIn summary, Aniket's extensive experience in AI model development, data processing, integration of external services, real-time analytics, and MLOps deployment makes him a valuable resource for various AI-related tasks. By clearly defining my needs and communicating effectively with him through his contact information, I can utilize his expertise to advance my projects.\\n</think>\\n\\nAniket Singh is an ideal partner for anyone seeking assistance in AI development due to his diverse and extensive experience in several key areas:\\n\\n1. **AI Model Development**: Aniket has hands-on experience with LLMs such as Llama3-8B, using frameworks like PyTorch, TensorFlow, and LangChain. He can guide you through developing AI models for various applications.\\n\\n2. **Data Processing Pipelines**: With expertise in high-throughput ETL pipelines, he can help optimize data flow, especially when handling large datasets efficiently.\\n\\n3. **Integration of External Services**: His knowledge of integrating services using MCP and handling web scraping or APIs is beneficial, particularly useful for fetching real-time data accurately.\\n\\n4. **Real-Time Analytics**: Aniket's experience in translating NLP into SQL can aid in creating systems that provide instant insights or reports based on user queries.\\n\\n5. **MLOps and Deployment**: His proficiency with Docker, AWS services, and deployment tools like Git/GitHub ensures scalable and efficient model environments.\\n\\n6. **NLP Techniques**: His background in techniques like IRT and RAG pipelines can enhance applications such as educational systems that require accurate query understanding.\\n\\nTo collaborate effectively, clearly outline your needs through email or LinkedIn messages. Whether it's building models, optimizing data pipelines, integrating services, real-time reporting, or MLOps deployment, Aniket's expertise will support your AI projects efficiently.\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(\"hi\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94911a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c71fbba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(chat , type=\"messages\").launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
